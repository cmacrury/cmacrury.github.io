---
---

@string{aps = {American Physical Society,}}


@inproceedings{duppala2024,
author ={ Sharmila Duppala and Nathaniel
Grammel and Juan Luque and Calum MacRury and Aravind Srinivasan},
title ={Proportionally Fair Matching Algorithms via Randomized Rounding},
booktitle = {the Annual AAAI Conference on Artificial Intelligence (AAAI)},
year = {2025},
}




@article{borodin2023probe,
  author       = {Allan Borodin and
                  Calum MacRury},
  title        = {Online Bipartite Matching in the Probe-Commit Model},
  volume       = {abs/2303.08908},
  journal      = {Accepted to Mathematical Programming},
  year         = {2024},
  url          = {https://doi.org/10.48550/arXiv.2303.08908},
  doi          = {10.48550/ARXIV.2303.08908},
  eprinttype    = {arXiv},
  note = {Journal version of ``Secretary Matching Meets Probing with Commitment'' and ``Prophet Matching in the Probe-Commit Model''.},
  arxiv = {2303.08908},
  pdf = {posted_papers/borodin_2023_probe.pdf},
  eprint       = {2303.08908},
  timestamp    = {Mon, 20 Mar 2023 15:23:19 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2303-08908.bib},
  selected = {true},	
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}





@inproceedings{ma2024vanishing,
author = {Will Ma and Calum MacRury and Pranav Nuti},
title = {Online Matching and Contention Resolution for Edge Arrivals with Vanishing Probabilities},
booktitle = {the ACM Conference on Economics and Computation (EC)},
year = {2024},
abstract = {We study the performance of sequential contention resolution and matching algorithms on random graphs with vanishing edge probabilities. The regime with vanishing edge probabilities is interesting for several reasons: 1) in applications such as online advertising, an edge represents a customer clicking an ad and the probability of any such event is tiny; 2) in settings where worst-case instances for contention resolution schemes are known, they have vanishing edge probabilities; 3) this is the main regime of interest in the literature on Erdős–Rényi random graphs.

When the edges of the graph are processed in an adversarially-chosen order, we derive a new OCRS that is $0.382$-selectable, attaining the "independence benchmark" from the literature under the vanishing edge probabilities assumption.
Complementary to this positive result, we show that no OCRS can be more than $0.390$-selectable, significantly improving upon the upper bound of $0.428$ from the literature.
Meanwhile, when the edges of the graph are processed in a uniformly random order, we show that the simple greedy CRS which accepts all active and feasible edges is $1/2$-selectable.
This result is tight due to a known upper bound.
Finally, when the algorithm can choose the processing order, we show that a slight tweak to the random order---give each vertex a random priority and process edges in lexicographic order---results in a strictly better OCRS that is $1-log(2-1/e)\approx 0.510$-selectable.
Our positive results also apply to online matching on $1$-uniform random graphs with vanishing (non-identical) edge probabilities, extending and unifying some results from that literature.},
arXiv={2406.14506},
selected = {true},
pdf = {posted_papers/ma_2024_vanishing.pdf}
}




@inproceedings{macrury2023induction,
  author       = {Calum MacRury and
                  Will Ma},
  title        = {Random-order Contention Resolution via Continuous Induction: Tightness
                  for Bipartite Matching under Vertex Arrivals},
  booktitle      = {the Annual ACM Symposium on Theory of Computing (STOC)},
  volume       = {abs/2310.10101},
  year         = {2024},
  arXiv = {2310.10101},
  url          = {https://doi.org/10.48550/arXiv.2310.10101},
  doi          = {10.48550/ARXIV.2310.10101},
  eprinttype    = {arXiv},
  eprint       = {2310.10101},
  timestamp    = {Wed, 25 Oct 2023 17:11:46 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2310-10101.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org},
 arXiv = {2310.10101},
 abstract = {We introduce a new approach for designing Random-order Contention Resolution Schemes (RCRS's) via exact solution in continuous time. Given a function $c(y):[0,1] \rightarrow [0,1]$,
we show how to select each element which arrives at time $y \in [0,1]$ with probability \textit{exactly} $c(y)$.
We provide a rigorous algorithmic framework for achieving this, which discretizes the time interval and also needs to sample its past execution to ensure these exact selection probabilities.
We showcase
our framework in the context of online contention resolution schemes for matching with random-order vertex arrivals. For bipartite graphs with two-sided arrivals, we design a $(1+e^{-2})/2 \approx 0.567$-selectable RCRS, which we also show to be tight.
Next, we show that the presence of short odd-length cycles is the only barrier to attaining a (tight) $(1+e^{-2})/2$-selectable RCRS on general graphs. By generalizing our bipartite RCRS, we design an RCRS for graphs with odd-length girth $g$ which is $(1+e^{-2})/2$-selectable as $g \rightarrow \infty$. This convergence happens very rapidly: for triangle-free
graphs (i.e., $g \ge 5$), we attain a  $121/240 + 7/16 e^2 \approx 0.563$-selectable RCRS.
Finally, for general graphs we improve on the $8/15 \approx 0.533$-selectable RCRS of (Fu et al., 2021) and design an RCRS which is at least $0.535$-selectable.
Due to the reduction of (Ezra et al., 2020), our bounds yield a $0.535$-competitive (respectively, $(1+e^{-2})/2$-competitive) algorithm for prophet secretary matching
on general (respectively, bipartite) graphs under vertex arrivals.},
selected = {true},
pdf = {posted_papers/macrury_2023_induction.pdf},
html = {https://dl.acm.org/doi/10.1145/3618260.3649788}
}







@article{macrury2022threshold,
  author    = {Calum MacRury and
               Erlang Surya},
  title     = {Sharp Thresholds in Adaptive Random Graph Processes},
  volume    = {abs/2207.14469},
  year      = {2023},
  url       = {https://doi.org/10.48550/arXiv.2207.14469},
  doi       = {10.48550/arXiv.2207.14469},
  journal = {Random Structures and Algorithms},
  arXiv  = {2207.14469},
  timestamp = {Tue, 02 Aug 2022 15:25:29 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2207-14469.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract ={The D-process is a single player game in which the player is initially presented the empty graph on n vertices. In each step, a subset of edges X is independently sampled according to a distribution D. The player then selects one edge e from X, and adds e to its current graph. For a fixed monotone increasing graph property P, the objective of the player is to force the graph to satisfy P in as few steps as possible. Through appropriate choices of D, the D-process generalizes well-studied adaptive random graph processes, such as the Achlioptas process and the semi-random graph process
We prove a sufficient condition for the existence of a sharp threshold for P in the D-process. For the semi-random process, we use this condition to prove the existence of a sharp threshold when P corresponds to being Hamiltonian or to containing a perfect matching. These are the first results for the semi-random graph process which show the existence of a sharp threshold when P corresponds to containing a sparse spanning graph. Using a separate analytic argument, we show that each sharp threshold is of the form CPn for some fixed constant CP>0. This answers two of the open problems proposed by Ben-Eliezer et al. (SODA 2020) in the affirmative. Unlike similar results which establish sharp thresholds for certain distributions and properties, we establish the existence of sharp thresholds without explicitly identifying asymptotically optimal strategies.},
  pdf = {posted_papers/macrury_2023_thresholds.pdf},
html = {https://onlinelibrary.wiley.com/doi/full/10.1002/rsa.21197},
selected = {true},
}




@article{macrury2022transport,
	title ={Optimizing Transport Frequency in Multi-Layered Urban
	Transportation Networks for Pandemic Prevention},
	journal = {Public Transport},
	year = {2023},
	author = {Calum MacRury and Nykyta Polituchyi and Paweł Prałat and Kinga Siuta and Przemysław Szufel},
	abstract = {In this paper, we identify determinants of pandemic spread in urban populations. Specifically, we develop a multi-agent simulation framework to model virus spread in complex networks.
	Our agents periodically commute between home and work via a combination of walking routes
	and public transit, and make decisions intelligently based upon their location, available routes,
	and expectations of public transport arrival times. Our infection scheme allows for different
	contagiousness levels, as a function of the virus’s strain and where the agents interact (i.e.,
	inside or outside). Our results show that the pandemic’s scale is heavily impacted by the network’s structure, and the decision making of the agents. In particular, the progression of the
	pandemic greatly differs when agents primarily infect each other in a crowded urban transportation system, opposed to while walking. Additionally, the results show that local subgraph
	characteristics, including topology, structure, and statistics such as its degree distribution and
	density, affect the viruses’ transmission rates. We also assess the effect of modifying the public
	transport’s running frequency on the spread of two different virus strains (with different levels
	of contagiousness). In particular, lowering the running frequency can discourage agents from
	taking public transportation too often, especially for shorter distances. On the other hand, the
	low frequency contributes to more crowded streetcars or subway cars if the policy is not designed
	correctly, which is why such an analysis may prove valuable for finding “sweet spots” that optimize the system. The proposed approach has been validated on real world data, and a model
	of the transportation network of downtown Toronto. The framework used is flexible and can
	be easily adjusted to model other urban environments, and additional forms of transportation
	(such as carpooling, ride-share and more).},
	pdf = {posted_papers/macrury_2022_transport.pdf},
      html = {https://link.springer.com/article/10.1007/s12469-024-00351-0}
	
}







@article{macrury2022contention,
	author    = {Calum MacRury and
	Will Ma and Nathaniel Grammel},
	title     = {On (Random-order) Online Contention Resolution Schemes for the Matching Polytope of (Bipartite) Graphs},
	year ={2024},
	journal = {Operations Research},
	eprinttype = {arXiv},
      note = {Conference version appeared in the {ACM-SIAM} Symposium on Discrete
	Algorithms (SODA 2023)},
	arXiv  = {2209.07520},
	abstract ={Online Contention Resolution Schemes (OCRS's) represent a modern tool for selecting a subset of elements, subject to resource constraints, when the elements are presented to the algorithm sequentially. OCRS's have led to some of the best-known competitive ratio guarantees for online resource allocation problems, with the added benefit of treating different online decisions -- accept/reject, probing, pricing -- in a unified manner. This paper analyzes OCRS's for resource constraints defined by matchings in graphs, a fundamental structure in combinatorial optimization. We consider two dimensions of variants: the elements being presented in adversarial or random order; and the graph being bipartite or general. We improve the state of the art for all combinations of variants, both in terms of algorithmic guarantees and impossibility results. Some of our algorithmic guarantees are best-known even compared to Contention Resolution Schemes that can choose the order of arrival or are offline. All in all, our results for OCRS directly improve the best-known competitive ratios for online accept/reject, probing, and pricing problems on graphs in a unified manner.},
	pdf = {posted_papers/macrury_2024_contention.pdf},
      selected= {true},
      html = {https://pubsonline.informs.org/doi/10.1287/opre.2023.0339}
}





@inproceedings{gao2022hamiltonian,
  	  title = {A Fully Adaptive Strategy for Hamiltonian Cycles in the Semi-Random Graph Process},
  	  author = {Pu Gao and Calum MacRury and Paweł Prałat},
      year={2022},
      booktitle={the International Conference on Randomization and
Computation (RANDOM)},
      eprint={2102.04325},
      archivePrefix={arXiv},
      primaryClass={cs.DM},
      arxiv = {2205.02350},
      html ={https://drops.dagstuhl.de/opus/volltexte/2022/17151/},
	 abstract = {The semi-random graph process is a single player game in which the player is initially presented an empty graph on $n$ vertices. In each round, a vertex $u$ is presented to the player independently and uniformly at random. The player then adaptively selects a vertex $v$, and adds the edge $uv$ to the graph. For a fixed monotone graph property, the objective of the player is to force the graph to satisfy this property with high probability in as few rounds as possible.

We focus on the problem of constructing a Hamiltonian cycle in as few rounds as possible. In particular, we present an adaptive strategy for the player which achieves it in $\alpha n$ rounds, where $\alpha < 2.01678$ is derived from the solution to some system of differential equations. We also show that the player cannot achieve the desired property in less than $\beta n$ rounds, where $\beta > 1.26575$. These results improve the previously best known bounds and, as a result, the gap between the upper and lower bounds is decreased from 1.39162 to 0.75102.},
      pdf = {posted_papers/gao_2022_hamiltonian.pdf},
}




@inproceedings{borodin2021prophet,
      title={Prophet Matching in the Probe-Commit Model}, 
      author={Allan Borodin and Calum MacRury and Akash Rakheja},
      booktitle={the International Conference on Approximation Algorithms for Combinatorial
Optimization Problems (APPROX)},
      year={2022},
      eprint={2102.04325},
      archivePrefix={arXiv},
      primaryClass={cs.DM},
      arxiv = {2102.04325},
       html={https://drops.dagstuhl.de/opus/volltexte/2022/17168/},
      abstract = {
We consider the online bipartite stochastic matching problem with known i.d. (independently distributed) online vertex arrivals. In this problem, when an online vertex arrives, its weighted edges must be
probed (queried) to determine if they exist, based on known edge probabilities. Our algorithms operate
in the probe-commit model, in that if a probed edge exists, it must be used in the matching. Additionally,
each online node has a downward-closed probing constraint on its adjacent edges which indicates which
sequences of edge probes are allowable. Our setting generalizes the commonly studied patience (or timeout) constraint which limits the number of probes that can be made to an online node’s adjacent edges.
Most notably, this includes non-uniform edge probing costs (specified by knapsack/budget constraint).
We extend a recently introduced configuration LP to the known i.d. setting, and also provide the first
proof that it is a relaxation of an optimal offline probing algorithm (the offline adaptive benchmark). Using this LP,
we establish new competitive bounds all of which generalize the standard non-stochastic setting when edges do not need to be probed (i.e., exist with certainty). 
      },
      pdf = {posted_papers/borodin_2021_prophet.pdf}
}






@article{macrury2022phase,
      title={The Phase Transition of Discrepancy in Random Hypergraphs}, 
      author={Calum MacRury and Tomáš Masařík and Leilani Pai and Xavier Pérez-Giménez},
      year={2023},
      eprint={2102.07342},
      journal = {SIAM Journal on Discrete Mathematics},
      archivePrefix={arXiv},
      primaryClass={math.CO},
      arxiv={2102.07342},
      html = {https://epubs.siam.org/doi/10.1137/21M1451427},
      pdf = {posted_papers/macrury_2023_discrepancy.pdf},
      abstract={Motivated by the Beck-Fiala conjecture, we study the discrepancy problem in two related models of random hypergraphs on $n$ vertices and $m$ edges. In the first ({\em edge-independent}) model, a random hypergraph $H_1$ is constructed by fixing a parameter $p$ and allowing each of the $n$ vertices to join each of the $m$ edges independently with probability $p$. In the parameter range in which $pn \rightarrow \infty$ and $pm \rightarrow \infty$, we show that with high probability (\whp) $H_1$ has discrepancy at least $\Omega(2^{-n/m} \sqrt{pn})$ when $m = O(n)$, and at least $\Omega(\sqrt{pn \log\gamma })$ when $m \gg n$,
where $\gamma = \min\{ m/n, pn\}$. In the second ({\em edge-dependent}) model, $d$ is fixed and each vertex of $H_2$ independently joins exactly $d$ edges uniformly at random.
We obtain analogous results for this model by generalizing the techniques used for the edge-independent model with $p=d/m$. Namely, for $d \rightarrow \infty$ and $dn/m \rightarrow \infty$, we prove that \whp\ $H_{2}$ has discrepancy at least $\Omega(2^{-n/m} \sqrt{dn/m})$ when $m = O(n)$, and at least $\Omega(\sqrt{(dn/m) \log\gamma})$ when $m \gg n$, where $\gamma =\min\{m/n, dn/m\}$. 
Furthermore, we obtain nearly matching asymptotic upper bounds on the discrepancy in both models (when $p=d/m$), in the dense regime of $m \gg n$. Specifically, we apply the partial colouring lemma of Lovett and Meka to show that \whp\ $H_{1}$ and $H_{2}$ each have discrepancy $O( \sqrt{dn/m}  \log(m/n))$, provided $d \rightarrow \infty$, $d n/m \rightarrow \infty$ and $m \gg n$. This result is algorithmic, and together with the work of Bansal and Meka characterizes how the discrepancy of each random hypergraph model transitions from $\Theta(\sqrt{d})$ to $o(\sqrt{d})$ as $m$ varies from $m=\Theta(n)$ to $m \gg n$.}
}





@article{gao2021perfect,
      title={Perfect Matchings in the Semi-random Graph Process}, 
      author={Pu Gao and Calum MacRury and Pra\l{}at, Pawe\l{}},
      year={2022},
      journal = {SIAM Journal on Discrete Mathematics},
      eprint={2105.13455},
      doi = {10.1137/21M1446939},
      html={https://epubs.siam.org/doi/10.1137/21M1446939},
      archivePrefix={arXiv},
      primaryClass={math.CO},
      pdf = {posted_papers/gao_2022_matching.pdf},
      arxiv={2105.13455},
      abstract={
		The semi-random graph process is a single player game in which the player is initially presented an empty graph on $n$ vertices. In each round, a vertex $u$ is presented to the player independently and uniformly at random. The player then adaptively selects a vertex $v$, and adds the edge $uv$ to the graph. For a fixed monotone graph property, the objective of the player is to force the graph to satisfy this property with high probability in as few rounds as possible.

We focus on the problem of constructing a perfect matching in as few rounds as possible. In particular, we present an adaptive strategy for the player which achieves a perfect matching in $\beta n$ rounds, where the value of $\beta < 1.206$ is derived from a solution to some system of differential equations. This improves upon the previously best known upper bound of $(1+2/e+o(1)) \, n < 1.736 \, n$ rounds. We also improve the previously best lower bound of $(\ln 2 + o(1)) \, n > 0.693 \, n$ and show that the player cannot achieve the desired property in less than $\alpha n$ rounds, where the value of $\alpha > 0.932$ is derived from a solution to another system of differential equations. As a result, the gap between the upper and lower bounds is decreased roughly four times.      }
}



@article{bonato_2020_probabilistically,
  title={Algorithms for $p$-Faulty Search on a Half-Line},
  author={Bonato, Anthony and Georgiou, Konstantinos and MacRury, Calum and Pra\l{}at, Pawe\l{}},
  arxiv={2002.07797},
  JOURNAL={Algorithmica},
  year={2022},
  doi = {10.1007/s00453-022-01075-y},
  note ={Conference version appeared in LATIN 2020},
  abstract = {We study p-Faulty Search, a variant of the classic cow-path optimization problem, where a unit speed robot searches the half-line (or 1-ray) for a hidden item. The searcher is probabilistically faulty, and detection of the item with each visitation is an independent Bernoulli trial whose probability of success p is known. The objective is to minimize the worst case expected detection time, relative to the distance of the hidden item to the origin. A variation of the same problem was first proposed by Gal in 1980. Then in 2003, Alpern and Gal [The Theory of Search Games and Rendezvous] proposed a so-called monotone solution for searching the line (2-rays); that is, a trajectory in which the newly searched space increases monotonically in each ray and in each iteration. Moreover, they conjectured that an optimal trajectory for the 2-rays problem must be monotone. We disprove this conjecture when the search domain is the half-line (1-ray). We provide a lower bound for all monotone algorithms, which we also match with an upper bound. Our main contribution is the design and analysis of a sequence of refined search strategies, outside the family of monotone algorithms, which we call t-sub-monotone algorithms. Such algorithms induce performance that is strictly decreasing with t, and for all p \in (0,1). The value of t quantifies, in a certain sense, how much our algorithms deviate from being monotone, demonstrating that monotone algorithms are sub-optimal when searching the half-line.},
html = {https://link.springer.com/article/10.1007/s00453-022-01075-y},
pdf = {posted_papers/bonato_2020_prob.pdf}
}


@article{bonato_2018_robot,
title = "The Robot Crawler Graph Process",
journal = "Discrete Applied Mathematics",
volume = "247",
pages = "23 - 36",
year = "2018",
issn = "0166-218X",
note = {Conference version appeared in WAW 2015},
doi = "https://doi.org/10.1016/j.dam.2018.01.018",
url = "http://www.sciencedirect.com/science/article/pii/S0166218X18301227",
author = "Anthony Bonato and Rita M. {del Río-Chanona} and Calum MacRury and Jake Nicolaidis and Xavier Pérez-Giménez and Paweł Prałat and Kirill Ternovsky",
keywords = "Deterministic walk, Graph searching, Random graph, Preferential attachment model",
abstract = "Information gathering by crawlers on the web is of practical interest. We consider a simplified model for crawling complex networks such as the web graph, which is a variation of the robot vacuum edge-cleaning process of Messinger and Nowakowski. In our model, a crawler visits nodes via a deterministic walk determined by their weightings which change during the process deterministically. The minimum, maximum, and average time for the robot crawler to visit all the nodes of a graph is considered on various graph classes such as trees, multi-partite graphs, binomial random graphs, and graphs generated by the preferential attachment model.",
html={https://www.sciencedirect.com/science/article/abs/pii/S0166218X18301227}
}





@article{dudek_2020_localization,
      title={Localization Game for Random Graphs}, 
      author={Andrzej Dudek and Sean English and Alan Frieze and Calum MacRury and Pra\l{}at, Pawe\l{}},
      year={2022},
      journal = {Discrete Applied Mathematics},
      eprint={1910.11225},
      archivePrefix={arXiv},
      primaryClass={math.CO},
      arxiv = {1910.11225},
      html = {https://www.sciencedirect.com/science/article/abs/pii/S0166218X21004819},
      abstract = {
      We consider the localization game played on graphs in which a cop tries to determine the exact location of an invisible robber by exploiting distance probes. The corresponding graph parameter \zeta(G) for a given graph G is called the localization number. In this paper, we improve the bounds for dense random graphs determining an asymptotic behaviour of \zeta(G). Moreover, we extend the argument to sparse graphs.},
	   pdf = {posted_papers/dudek_2020_localization.pdf}      
      
      
      }
}







@article{gao_2020_hamilton,
title = {Hamilton Cycles in the Semi-random Graph Process},
journal = {European Journal of Combinatorics},
volume = {99},
pages = {103423},
year = {2022},
issn = {0195-6698},
doi = {https://doi.org/10.1016/j.ejc.2021.103423},
arxiv = {2006.02599},
html = {https://www.sciencedirect.com/science/article/pii/S0195669821001165},
author = {Pu Gao and Bogumił Kamiński and Calum MacRury and Paweł Prałat},
abstract = {The semi-random graph process is a single player game in which the player is initially presented an empty graph on n vertices. In each round, a vertex u is presented to the player independently and uniformly at random. The player then adaptively selects a vertex v, and adds the edge uv to the graph. For a fixed monotone graph property, the objective of the player is to force the graph to satisfy this property with high probability in as few rounds as possible. We focus on the problem of constructing a Hamilton cycle in as few rounds as possible. In particular, we present a novel strategy for the player which achieves a Hamiltonian cycle in c∗n rounds, where the value of c∗ is the result of a high dimensional optimization problem. Numerical computations indicate that c∗<2.61135. This improves upon the previously best known upper bound of 3n rounds. We also show that the previously best lower bound of (ln2+ln(1+ln2)+o(1))n is not tight.},
pdf = {posted_papers/gao_2020_hamilton.pdf}
}




@inproceedings{borodin_2021_secretary,
      title={Secretary Matching Meets Probing with Commitment}, 
      author={Allan Borodin and Calum MacRury and Akash Rakheja},
      year={2021},
      booktitle={the International Conference on Approximation Algorithms for Combinatorial
Optimization Problems (APPROX)},
      eprint={2008.09260},
      archivePrefix={arXiv},
      primaryClass={cs.DS},
      arxiv = {2008.09260},
      html={https://drops.dagstuhl.de/opus/volltexte/2021/14706/},
      abstract={
Within the context of stochastic probing with commitment, we consider
the online stochastic matching problem; that is, the one-sided online bipartite
matching problem where edges adjacent to an online node must be probed to
determine if they exist based on edge probabilities that become known when an online vertex arrives.  If a probed edge
exists, it must be used in the matching (if possible). We consider the
competitiveness of online algorithms in both the adversarial order model (AOM)
and the random order model (ROM). More specifically, we consider a bipartite stochastic graph  
$G = (U,V,E)$ where $U$ is the set of offline vertices, $V$ is the set of online vertices and $G$
has edge probabilities $(p_{e})_{e \in E}$ and edge weights $(w_{e})_{e \in E}$.
Additionally, $G$ has probing constraints $(\scr{C}_{v})_{v \in V}$,  where $\scr{C}_v$
indicates which sequences of edges adjacent to an online vertex $v$ can be probed. We assume that $U$ is
known in advance, and that $\scr{C}_v$, together with the
edge probabilities and weights adjacent to an online vertex  are only revealed  when the online vertex arrives. 
This model generalizes the various settings of the classical bipartite matching problem,
and so our main contribution is in making progress towards understanding which classical results extend to the stochastic
probing model.
},

 pdf = {posted_papers/borodin_2021_secretary.pdf}

}






@article{english_zero_forcing_2021,
title = "Probabilistic Zero Forcing on Random Graphs",
journal = "European Journal of Combinatorics",
volume = "91",
pages = "103207",
year = "2021",
issn = "0195-6698",
doi = "https://doi.org/10.1016/j.ejc.2020.103207",
url = "http://www.sciencedirect.com/science/article/pii/S0195669820301281",
author = "Sean English and Calum MacRury and Paweł Prałat",
arxiv = {1909.06568},
abstract = "Zero forcing is a deterministic iterative graph coloring process in which vertices are colored either blue or white, and in every round, any blue vertices that have a single white neighbor force these white vertices to become blue. Here we study probabilistic zero forcing, where blue vertices have a non-zero probability of forcing each white neighbor to become blue. 

We explore the propagation time for probabilistic zero forcing on the Erd\H{o}s-R\'eyni random graph G(n,p) when we start with a single vertex colored blue. We show that when p=\log^{-o(1)}n, then with high probability it takes (1+o(1))\log_2 \log_2 n rounds for all the vertices in G(n,p) to become blue, and when \log n/n \ll p \le \log^{-O(1)} n, then with high probability it takes \Theta(\log(1/p)) rounds.",
html = {https://www.sciencedirect.com/science/article/pii/S0195669820301281}
}


@article{jakobson_ben_conv_2018,
author = {Jakobson, Dmitry and MacRury, Calum and Norin, Sergey and Turner, Lise},
year = {2018},
pages = {},
title = {Distribution of Coefficients of Rank Polynomials for Random Sparse Graphs},
volume = {25},
journal = {The Electronic Journal of Combinatorics},
doi = {10.37236/7133},
pdf = {posted_papers/jakobson_ben_conv_2018.pdf},
abstract = {
We study the distribution of coefficients of rank polynomials of random sparse graphs.  We first discuss the limiting distribution for general graph sequences that converge in the sense of Benjamini-Schramm.  Then we compute the limiting distri-bution and Newton polygons of the coefficients of the rank polynomial of randomd-regular graphs.},
html ={https://www.combinatorics.org/ojs/index.php/eljc/article/view/v25i4p50}
}


@article{bal_2018_zero,
      title={Zero Forcing Number of Random Regular Graphs}, 
      author={Deepak Bal and Patrick Bennett and Sean English and Calum MacRury and Paweł Prałat},
      year={2021},
      volume = {12},
      pages = {85-116},
      primaryClass={math.CO},
      journal = {Journal of Combinatorics},
      abstract = {
      The zero forcing process is an iterative graph colouring process in which at each time step a coloured vertex with a single uncoloured neighbour can force this neighbour to become coloured. A zero forcing set of a graph is an initial set of coloured vertices that can eventually force the entire graph to be coloured. The zero forcing number is the size of the smallest zero forcing set. We explore the zero forcing number for random regular graphs, improving on bounds given by Kalinowski, Kam\u{c}ev and Sudakov. We also propose and analyze a degree greedy algorithm for finding small zero forcing sets using the differential equations method.},
     

html = {https://www.intlpress.com/site/pub/pages/journals/items/joc/content/vols/0012/0001/a004/index.php?mode=ns},     
     
arxiv = {1812.06477},

pdf = {posted_papers/bal_2018_zero.pdf}
}

